{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Laboratorio sobre Spark**\n",
    "\n",
    "# **Alunos:**\n",
    "- Pedro Lucas Siqueira Fernandes(190115564)\n",
    "- Pablo Guilherme de J B Silva(200025791)\n",
    "- João Lucas Pinto Vasconcelos (190089601)\n",
    "- Arthur Taylor de Jesus Popov (190084642)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' n�o � reconhecido como um comando interno\n",
      "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instalando a biblioteca que permite copiar conteúdos do Gdrive compartilhado do professor\u001b[39;00m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install gdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgdown\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gdown'"
     ]
    }
   ],
   "source": [
    "# Instalando a biblioteca que permite copiar conteúdos do Gdrive compartilhado do professor\n",
    "!pip install gdown\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiando a pasta de laboratório (material do professor) para o contexto do aluno\n",
    "url = 'https://drive.google.com/drive/folders/1z_l8RO6YYwjLdPrMBtnSNpfzfznJt1ja'\n",
    "gdown.download_folder(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de variaveis e instalação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as variáveis de ambiente do Spark \n",
    "import os\n",
    "# Variáveis gerais\n",
    "os.environ['JAVA_HOME']=\"/usr/lib/jvm/java-11-openjdk-amd64\" # readlink -f /usr/bin/javac\n",
    "os.environ['BASHRC_PATH']= \"/root/.bashrc\"\n",
    "# Variáveis específicas do Spark\n",
    "os.environ['SPARK_INSTALL_DIR']=\"/content\"\n",
    "os.environ['SPARK_HOME']=\"/content/spark\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiando os fonte do hadoop para a pasta $SPARK_INSTALL_DIR\n",
    "!wget https://downloads.apache.org/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz -P $SPARK_INSTALL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descompactando os arquivos do hadoop na pasta $SPARK_INSTALL_DIR\n",
    "!tar -xvzf $SPARK_INSTALL_DIR/spark-3.5.4-bin-hadoop3.tgz -C $SPARK_INSTALL_DIR\n",
    "!mv $SPARK_INSTALL_DIR/spark-3.5.4-bin-hadoop3 $SPARK_INSTALL_DIR/spark\n",
    "!rm $SPARK_INSTALL_DIR/spark-3.5.4-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ativando servidor Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'$SPARK_HOME' n�o � reconhecido como um comando interno\n",
      "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# Iniciando os processos NameNode e DataNode, daemons do HDFS\n",
    "!$SPARK_HOME/sbin/start-master.sh --host localhost --port 7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando os processos relativos ao gerenciador de recursos YARN\n",
    "!$SPARK_HOME/sbin/start-worker.sh spark://localhost:7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark\n",
    "#!$SPARK_HOME/bin/pyspark --master spark://localhost:7077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando o KAFKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' n�o � reconhecido como um comando interno\n",
      "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# Instalando o kafka python\n",
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo os imports de Producer e Consumer do Kafka\n",
    "from kafka import KafkaProducer\n",
    "from kafka import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo download do binário do kafka\n",
    "!curl -sSOL https://dlcdn.apache.org/kafka/3.8.0/kafka_2.13-3.8.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descompactando o kafka e criando um link para a pasta do kafka\n",
    "!tar xvfz kafka_2.13-3.8.0.tgz\n",
    "!ln -s kafka_2.13-3.8.0 kafka\n",
    "!rm kafka_2.13-3.8.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ativando os daemons do kafka...\n",
    "!./kafka/bin/zookeeper-server-start.sh -daemon ./kafka/config/zookeeper.properties\n",
    "!./kafka/bin/kafka-server-start.sh -daemon ./kafka/config/server.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install confluent_kafka"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
